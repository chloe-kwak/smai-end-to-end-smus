{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1fb9d9-fed0-46af-b2ad-cd9a75b53c47",
   "metadata": {},
   "source": [
    "# [Lab3] 모델 성능 평가 및 비교\n",
    "\n",
    "이 노트북에서는 훈련된 두 모델의 성능을 평가하고 비교합니다.\n",
    "\n",
    "## 주요 내용\n",
    "- 로컬 환경에서 모델 테스트\n",
    "- 모델 성능 비교 및 평가\n",
    "- 혼동 행렬 및 분류 리포트 생성\n",
    "- MLflow를 통한 실험 추적\n",
    "- 최고 성능 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ef172-06cd-4775-9823-c749fe2e2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 노트북에서 저장한 변수들 로드\n",
    "%store -r\n",
    "\n",
    "print(\"✅ 저장된 변수들을 로드했습니다.\")\n",
    "print(f\"   - 등록된 모델 이름: {registered_model_name}\")\n",
    "print(f\"   - 모델 버전 1: {registered_model_version_1.version}\")\n",
    "print(f\"   - 모델 버전 2: {registered_model_version_2.version}\")\n",
    "print(f\"   - MLflow 실행 ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3fc679-a32e-40b5-9f0c-af1d3a6358f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker_studio import Project\n",
    "\n",
    "# AWS 세션 초기화\n",
    "boto_session = boto3.Session()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 및 세션 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-setup",
   "metadata": {},
   "source": [
    "## 2. 프로젝트 및 MLflow 설정\n",
    "\n",
    "Project 클래스를 사용하여 일관된 리소스 접근을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project-mlflow-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 및 MLflow 설정\n",
    "project = Project()\n",
    "arn = project.mlflow_tracking_server_arn\n",
    "role = project.iam_role\n",
    "\n",
    "# MLflow 연결\n",
    "mlflow.set_tracking_uri(arn)\n",
    "\n",
    "print(f\"✅ 프로젝트 및 MLflow 설정 완료\")\n",
    "print(f\"   - MLflow URI: {arn}\")\n",
    "print(f\"   - IAM 역할: {role}\")\n",
    "print(f\"   - 등록된 모델 이름: {registered_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## 3. 테스트 데이터 로드\n",
    "\n",
    "전처리된 테스트 데이터를 로드하여 모델 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-tmp-dir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 디렉토리 생성\n",
    "!mkdir -p tmp\n",
    "\n",
    "print(\"✅ 임시 디렉토리 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-test-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3에서 테스트 데이터 다운로드\n",
    "print(\"📥 테스트 데이터 다운로드 중...\")\n",
    "\n",
    "!aws s3 cp $test_path/test_x.csv tmp/test_x.csv\n",
    "!aws s3 cp $test_path/test_y.csv tmp/test_y.csv\n",
    "\n",
    "print(\"✅ 테스트 데이터 다운로드 완료\")\n",
    "print(f\"   - 특성 데이터: tmp/test_x.csv\")\n",
    "print(f\"   - 레이블 데이터: tmp/test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-test-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "print(\"📊 테스트 데이터 로드 중...\")\n",
    "\n",
    "test_x = pd.read_csv('tmp/test_x.csv', names=[f'{i}' for i in range(59)])\n",
    "test_y = pd.read_csv('tmp/test_y.csv', names=['y'])\n",
    "\n",
    "print(f\"✅ 테스트 데이터 로드 완료\")\n",
    "print(f\"   - 테스트 샘플 수: {len(test_x)}\")\n",
    "print(f\"   - 특성 수: {test_x.shape[1]}\")\n",
    "print(f\"   - 양성 클래스 비율: {test_y['y'].mean():.3f}\")\n",
    "\n",
    "# 데이터 미리보기\n",
    "print(f\"\\n📋 데이터 미리보기:\")\n",
    "print(f\"   - 특성 데이터 형태: {test_x.shape}\")\n",
    "print(f\"   - 레이블 분포: {test_y['y'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-loading-functions",
   "metadata": {},
   "source": [
    "## 4. 모델 로드 함수 정의\n",
    "\n",
    "MLflow Model Registry와 S3에서 모델을 로드하는 함수들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-load-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등록된 모델 상태 확인\n",
    "try:\n",
    "    client = mlflow.MlflowClient()\n",
    "    \n",
    "    # 모델 버전 정보 확인\n",
    "    model_version_1 = client.get_model_version(\n",
    "        name=registered_model_name,\n",
    "        version=registered_model_version_1.version\n",
    "    )\n",
    "    \n",
    "    print(f\"📋 모델 1 정보:\")\n",
    "    print(f\"   - 이름: {model_version_1.name}\")\n",
    "    print(f\"   - 버전: {model_version_1.version}\")\n",
    "    print(f\"   - 상태: {model_version_1.status}\")\n",
    "    print(f\"   - 단계: {model_version_1.current_stage}\")\n",
    "    print(f\"   - 소스: {model_version_1.source}\")\n",
    "    \n",
    "    MODEL_REGISTRY_AVAILABLE = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Model Registry 접근 실패: {e}\")\n",
    "    print(\"S3에서 직접 모델을 로드합니다.\")\n",
    "    MODEL_REGISTRY_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model-objects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-test-and-deploy.ipynb에서 사용할 모델 객체 생성\n",
    "# 이 변수들은 2-training.ipynb에서 생성된 것들을 참조합니다\n",
    "\n",
    "print(\"🔧 배포용 모델 객체 생성 중...\")\n",
    "\n",
    "try:\n",
    "    # 2-training.ipynb에서 저장된 변수들이 있는지 확인\n",
    "    if 'xgb1' in locals() and 'xgb2' in locals():\n",
    "        print(\"✅ 훈련 단계에서 생성된 모델 객체를 사용합니다.\")\n",
    "        print(f\"   - xgb1 모델 데이터: {xgb1.model_data}\")\n",
    "        print(f\"   - xgb2 모델 데이터: {xgb2.model_data}\")\n",
    "    else:\n",
    "        print(\"⚠️ 훈련 단계의 모델 객체가 없습니다.\")\n",
    "        print(\"   배포 단계에서 직접 모델 URI를 사용하거나\")\n",
    "        print(\"   2-training.ipynb를 다시 실행해주세요.\")\n",
    "        \n",
    "        # 대안: 저장된 모델 URI 사용 (있다면)\n",
    "        if 'model1_uri' in locals() and 'model2_uri' in locals():\n",
    "            print(\"\\n💡 저장된 모델 URI를 사용합니다:\")\n",
    "            print(f\"   - 모델 1 URI: {model1_uri}\")\n",
    "            print(f\"   - 모델 2 URI: {model2_uri}\")\n",
    "            \n",
    "            # 간단한 모델 객체 생성 (URI만 포함)\n",
    "            class SimpleModelRef:\n",
    "                def __init__(self, model_data):\n",
    "                    self.model_data = model_data\n",
    "            \n",
    "            xgb1 = SimpleModelRef(model1_uri)\n",
    "            xgb2 = SimpleModelRef(model2_uri)\n",
    "            \n",
    "            print(\"✅ 간단한 모델 참조 객체를 생성했습니다.\")\n",
    "        else:\n",
    "            print(\"\\n❌ 모델 URI도 없습니다. 2-training.ipynb를 먼저 실행해주세요.\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 객체 생성 실패: {e}\")\n",
    "\n",
    "# 변수 저장 (다음 노트북에서 사용)\n",
    "if 'xgb1' in locals() and 'xgb2' in locals():\n",
    "    %store xgb1\n",
    "    %store xgb2\n",
    "    print(\"\\n💾 모델 객체를 저장했습니다 (xgb1, xgb2)\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 저장할 모델 객체가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model1-load-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_s3(model_data_uri, model_name=\"model\"):\n",
    "    \"\"\"S3에서 직접 XGBoost 모델을 로드하는 함수\"\"\"\n",
    "    import boto3\n",
    "    import tarfile\n",
    "    import pickle as pkl\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        print(f\"📥 {model_name} S3에서 로드 중: {model_data_uri}\")\n",
    "        \n",
    "        # S3에서 모델 다운로드\n",
    "        model_file = f\"./tmp/{model_name}-model.tar.gz\"\n",
    "        os.makedirs('./tmp', exist_ok=True)\n",
    "        \n",
    "        bucket, key = model_data_uri.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        boto3.client(\"s3\").download_file(bucket, key, model_file)\n",
    "        \n",
    "        # 압축 해제\n",
    "        with tarfile.open(model_file, \"r:gz\") as t:\n",
    "            t.extractall(path=\"./tmp\")\n",
    "        \n",
    "        # 모델 로드\n",
    "        model_path = \"./tmp/xgboost-model\"\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pkl.load(f)\n",
    "        \n",
    "        print(f\"✅ {model_name} 로드 성공\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {model_name} 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_model_from_mlflow(model_name, version):\n",
    "    \"\"\"MLflow Model Registry에서 모델을 로드하는 함수\"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}/{version}\"\n",
    "        print(f\"📥 MLflow에서 모델 로드 중: {model_uri}\")\n",
    "        \n",
    "        model = mlflow.xgboost.load_model(model_uri)\n",
    "        print(f\"✅ MLflow 모델 로드 성공\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ MLflow 모델 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ 모델 로드 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model1-testing",
   "metadata": {},
   "source": [
    "## 5. 모델 1 테스트 (보수적 하이퍼파라미터)\n",
    "\n",
    "첫 번째 모델을 로드하고 테스트 데이터로 예측을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95416524-70bc-4ff9-8b26-c73c9d82b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 모델 로드 및 테스트\n",
    "print(\"🔍 첫 번째 모델 (보수적 하이퍼파라미터) 테스트\")\n",
    "\n",
    "model1 = None\n",
    "\n",
    "# 방법 1: MLflow Model Registry에서 로드 시도\n",
    "if MODEL_REGISTRY_AVAILABLE:\n",
    "    model1 = load_model_from_mlflow(registered_model_name, registered_model_version_1.version)\n",
    "\n",
    "# 방법 2: MLflow 실패 시 S3에서 직접 로드\n",
    "if model1 is None:\n",
    "    print(\"MLflow 로드 실패, S3에서 직접 로드 시도...\")\n",
    "    model1 = load_model_from_s3(xgb1.model_data, \"model1\")\n",
    "\n",
    "# 모델 로드 성공 시 예측 수행\n",
    "if model1 is not None:\n",
    "    print(\"\\n📊 첫 번째 모델로 예측 수행 중...\")\n",
    "    \n",
    "    # XGBoost DMatrix 생성\n",
    "    dtest = xgb.DMatrix(test_x)\n",
    "    \n",
    "    # 예측 수행\n",
    "    predictions1 = model1.predict(dtest)\n",
    "    predictions1 = np.array(predictions1, dtype=float).squeeze()\n",
    "    \n",
    "    print(f\"✅ 예측 완료\")\n",
    "    print(f\"   - 예측 샘플 수: {len(predictions1)}\")\n",
    "    print(f\"   - 예측값 범위: {predictions1.min():.4f} ~ {predictions1.max():.4f}\")\n",
    "    print(f\"   - 평균 예측값: {predictions1.mean():.4f}\")\n",
    "    \n",
    "    # 예측 결과 미리보기\n",
    "    print(f\"\\n📋 첫 10개 예측값:\")\n",
    "    for i in range(min(10, len(predictions1))):\n",
    "        print(f\"   샘플 {i+1}: {predictions1[i]:.4f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 첫 번째 모델 로드 실패\")\n",
    "    predictions1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model2-testing",
   "metadata": {},
   "source": [
    "## 6. 모델 2 테스트 (적극적 하이퍼파라미터)\n",
    "\n",
    "두 번째 모델을 로드하고 테스트 데이터로 예측을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b397b-f07c-459d-b759-ece862c84a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 모델 로드 및 테스트\n",
    "print(\"🔍 두 번째 모델 (적극적 하이퍼파라미터) 테스트\")\n",
    "\n",
    "model2 = None\n",
    "\n",
    "# 방법 1: MLflow Model Registry에서 로드 시도\n",
    "if MODEL_REGISTRY_AVAILABLE:\n",
    "    model2 = load_model_from_mlflow(registered_model_name, registered_model_version_2.version)\n",
    "\n",
    "# 방법 2: MLflow 실패 시 S3에서 직접 로드\n",
    "if model2 is None:\n",
    "    print(\"MLflow 로드 실패, S3에서 직접 로드 시도...\")\n",
    "    model2 = load_model_from_s3(xgb2.model_data, \"model2\")\n",
    "\n",
    "# 모델 로드 성공 시 예측 수행\n",
    "if model2 is not None:\n",
    "    print(\"\\n📊 두 번째 모델로 예측 수행 중...\")\n",
    "    \n",
    "    # XGBoost DMatrix 생성\n",
    "    dtest = xgb.DMatrix(test_x)\n",
    "    \n",
    "    # 예측 수행\n",
    "    predictions2 = model2.predict(dtest)\n",
    "    predictions2 = np.array(predictions2, dtype=float).squeeze()\n",
    "    \n",
    "    print(f\"✅ 예측 완료\")\n",
    "    print(f\"   - 예측 샘플 수: {len(predictions2)}\")\n",
    "    print(f\"   - 예측값 범위: {predictions2.min():.4f} ~ {predictions2.max():.4f}\")\n",
    "    print(f\"   - 평균 예측값: {predictions2.mean():.4f}\")\n",
    "    \n",
    "    # 예측 결과 미리보기\n",
    "    print(f\"\\n📋 첫 10개 예측값:\")\n",
    "    for i in range(min(10, len(predictions2))):\n",
    "        print(f\"   샘플 {i+1}: {predictions2[i]:.4f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 두 번째 모델 로드 실패\")\n",
    "    predictions2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-comparison",
   "metadata": {},
   "source": [
    "## 7. 모델 성능 비교\n",
    "\n",
    "두 모델의 예측 결과를 비교하고 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 모델 모두 로드 성공한 경우 성능 비교\n",
    "if predictions1 is not None and predictions2 is not None:\n",
    "    print(\"📊 모델 성능 비교\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 이진 분류를 위한 임계값 설정 (0.5)\n",
    "    pred1_binary = (predictions1 > 0.5).astype(int)\n",
    "    pred2_binary = (predictions2 > 0.5).astype(int)\n",
    "    \n",
    "    # 실제 레이블\n",
    "    y_true = test_y['y'].values\n",
    "    \n",
    "    # AUC 점수\n",
    "    auc1 = roc_auc_score(y_true, predictions1)\n",
    "    auc2 = roc_auc_score(y_true, predictions2)\n",
    "    \n",
    "    # 정확도\n",
    "    acc1 = accuracy_score(y_true, pred1_binary)\n",
    "    acc2 = accuracy_score(y_true, pred2_binary)\n",
    "    \n",
    "    print(f\"🥇 모델 1 (보수적):\")\n",
    "    print(f\"   - AUC: {auc1:.4f}\")\n",
    "    print(f\"   - 정확도: {acc1:.4f}\")\n",
    "    \n",
    "    print(f\"\\n🥈 모델 2 (적극적):\")\n",
    "    print(f\"   - AUC: {auc2:.4f}\")\n",
    "    print(f\"   - 정확도: {acc2:.4f}\")\n",
    "    \n",
    "    # 최고 성능 모델 선택\n",
    "    if auc1 > auc2:\n",
    "        print(f\"\\n🏆 최고 성능: 모델 1 (AUC: {auc1:.4f})\")\n",
    "        best_model = model1\n",
    "        best_predictions = predictions1\n",
    "        best_model_name = \"보수적 하이퍼파라미터 모델\"\n",
    "        best_model_version = registered_model_version_1\n",
    "    else:\n",
    "        print(f\"\\n🏆 최고 성능: 모델 2 (AUC: {auc2:.4f})\")\n",
    "        best_model = model2\n",
    "        best_predictions = predictions2\n",
    "        best_model_name = \"적극적 하이퍼파라미터 모델\"\n",
    "        best_model_version = registered_model_version_2\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ 모델 로드 실패로 인해 성능 비교를 수행할 수 없습니다.\")\n",
    "    # 로드된 모델이 있다면 그것을 사용\n",
    "    if predictions1 is not None:\n",
    "        best_predictions = predictions1\n",
    "        best_model_name = \"보수적 하이퍼파라미터 모델\"\n",
    "        best_model_version = registered_model_version_1\n",
    "        print(f\"모델 1만 사용합니다: {best_model_name}\")\n",
    "    elif predictions2 is not None:\n",
    "        best_predictions = predictions2\n",
    "        best_model_name = \"적극적 하이퍼파라미터 모델\"\n",
    "        best_model_version = registered_model_version_2\n",
    "        print(f\"모델 2만 사용합니다: {best_model_name}\")\n",
    "    else:\n",
    "        print(\"❌ 사용 가능한 모델이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion-matrix-section",
   "metadata": {},
   "source": [
    "## 8. 혼동 행렬 및 분류 리포트\n",
    "\n",
    "최고 성능 모델의 상세한 성능 분석을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 (최고 성능 모델 기준)\n",
    "if 'best_predictions' in locals():\n",
    "    print(f\"📋 {best_model_name} 혼동 행렬:\")\n",
    "    \n",
    "    # 이진 분류 예측\n",
    "    best_pred_binary = (best_predictions > 0.5).astype(int)\n",
    "    \n",
    "    # 혼동 행렬 생성\n",
    "    confusion_matrix_df = pd.crosstab(\n",
    "        index=test_y['y'].values, \n",
    "        columns=best_pred_binary, \n",
    "        rownames=['실제값'], \n",
    "        colnames=['예측값']\n",
    "    )\n",
    "    \n",
    "    print(confusion_matrix_df)\n",
    "    \n",
    "    # 분류 리포트\n",
    "    print(f\"\\n📊 {best_model_name} 분류 리포트:\")\n",
    "    print(classification_report(test_y['y'].values, best_pred_binary))\n",
    "else:\n",
    "    print(\"⚠️ 평가할 모델이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## 9. 시각화 및 MLflow 실험 추적\n",
    "\n",
    "모델 성능을 시각화하고 MLflow에 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm, class_names, title=\"Confusion matrix\", cmap=plt.cm.Blues, normalize=False\n",
    "):\n",
    "    \"\"\"혼동 행렬을 시각화하는 함수\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(\n",
    "        xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        ylim=(cm.shape[0] - 0.5, -0.5),\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        title=title,\n",
    "        ylabel=\"Ground truth label\",\n",
    "        xlabel=\"Predicted label\",\n",
    "    )\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j,\n",
    "                i,\n",
    "                format(cm[i, j], fmt),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            )\n",
    "    fig.tight_layout()\n",
    "    return ax, fig\n",
    "\n",
    "print(\"✅ 시각화 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-confusion-matrix-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "if 'best_predictions' in locals():\n",
    "    print(f\"📊 {best_model_name} 혼동 행렬 시각화\")\n",
    "    \n",
    "    class_names = [\"no\", \"yes\"]\n",
    "    cm = confusion_matrix(test_y['y'].values, (best_predictions > 0.5).astype(int))\n",
    "    \n",
    "    ax, fig = plot_confusion_matrix(\n",
    "        cm, \n",
    "        class_names, \n",
    "        title=f\"{best_model_name} - Confusion Matrix\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ 혼동 행렬 시각화 완료\")\n",
    "else:\n",
    "    print(\"⚠️ 시각화할 모델이 없습니다.\")\n",
    "    fig = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlflow-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow에 혼동 행렬 로그\n",
    "if 'best_model_version' in locals() and fig is not None:\n",
    "    try:\n",
    "        print(f\"📝 MLflow에 혼동 행렬 로그 중...\")\n",
    "        print(f\"   - 모델: {best_model_version.name} 버전 {best_model_version.version}\")\n",
    "        \n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        with mlflow.start_run(run_id=best_model_version.run_id):\n",
    "            mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "            \n",
    "            # 추가 메트릭 로그\n",
    "            if predictions1 is not None and predictions2 is not None:\n",
    "                mlflow.log_metric(\"test_auc_model1\", auc1)\n",
    "                mlflow.log_metric(\"test_auc_model2\", auc2)\n",
    "                mlflow.log_metric(\"test_accuracy_model1\", acc1)\n",
    "                mlflow.log_metric(\"test_accuracy_model2\", acc2)\n",
    "        \n",
    "        print(\"✅ MLflow 로그 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ MLflow 로그 실패: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ MLflow 로그를 위한 데이터가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-summary",
   "metadata": {},
   "source": [
    "## 10. 결과 요약 및 저장\n",
    "\n",
    "모델 평가 결과를 요약하고 다음 노트북에서 사용할 변수들을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 요약\n",
    "print(\"📋 모델 평가 결과 요약\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'best_model_name' in locals():\n",
    "    print(f\"🏆 최고 성능 모델: {best_model_name}\")\n",
    "    \n",
    "    if predictions1 is not None and predictions2 is not None:\n",
    "        print(f\"\\n📊 성능 비교:\")\n",
    "        print(f\"   모델 1 (보수적): AUC={auc1:.4f}, 정확도={acc1:.4f}\")\n",
    "        print(f\"   모델 2 (적극적): AUC={auc2:.4f}, 정확도={acc2:.4f}\")\n",
    "        \n",
    "        # 성능 차이 계산\n",
    "        auc_diff = abs(auc1 - auc2)\n",
    "        acc_diff = abs(acc1 - acc2)\n",
    "        \n",
    "        print(f\"\\n📈 성능 차이:\")\n",
    "        print(f\"   AUC 차이: {auc_diff:.4f}\")\n",
    "        print(f\"   정확도 차이: {acc_diff:.4f}\")\n",
    "        \n",
    "    print(f\"\\n✅ 테스트 데이터 크기: {len(test_x)} 샘플\")\n",
    "    print(f\"✅ 양성 클래스 비율: {test_y['y'].mean():.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 모델 평가를 완료하지 못했습니다.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🎯 모델 평가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 노트북에서 사용할 변수들 저장\n",
    "if 'best_model_name' in locals():\n",
    "    %store best_model_name\n",
    "    %store best_model_version\n",
    "    \n",
    "    if 'best_predictions' in locals():\n",
    "        %store best_predictions\n",
    "    \n",
    "    print(\"✅ 변수 저장 완료:\")\n",
    "    print(f\"   - best_model_name: {best_model_name}\")\n",
    "    print(f\"   - best_model_version: {best_model_version.version}\")\n",
    "    print(f\"   - best_predictions: {len(best_predictions) if 'best_predictions' in locals() else 'N/A'} 개\")\n",
    "else:\n",
    "    print(\"⚠️ 저장할 변수가 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
