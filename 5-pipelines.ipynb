{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1759f18-ad7d-4645-a42f-a166b0435378",
   "metadata": {},
   "source": [
    "# [Lab5] SageMaker ML íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” SageMaker Pipelinesë¥¼ ì‚¬ìš©í•˜ì—¬ ì—”ë“œíˆ¬ì—”ë“œ ML ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ë‚´ìš©\n",
    "- SageMaker Pipelines ê°œë… ë° êµ¬ì„± ìš”ì†Œ\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë‹¨ê³„\n",
    "- ëª¨ë¸ í‰ê°€ ë° ì¡°ê±´ë¶€ ë“±ë¡\n",
    "- íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§\n",
    "- CI/CD ì›Œí¬í”Œë¡œìš° êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì €ì¥í•œ ë³€ìˆ˜ë“¤ ë¡œë“œ\n",
    "%store -r\n",
    "\n",
    "print(\"âœ… ì €ì¥ëœ ë³€ìˆ˜ë“¤ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "try:\n",
    "    print(f\"   - ì‹¤í—˜ ì´ë¦„: {experiment_name}\")\n",
    "    print(f\"   - ë“±ë¡ëœ ëª¨ë¸: {registered_model_name}\")\n",
    "    print(f\"   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name if 'best_model_name' in locals() else 'N/A'}\")\n",
    "except NameError:\n",
    "    print(\"   ì¼ë¶€ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import json\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker_studio import Project\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-setup",
   "metadata": {},
   "source": [
    "## 2. í”„ë¡œì íŠ¸ ë° íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "\n",
    "SageMaker AI í”„ë¡œì íŠ¸ì™€ íŒŒì´í”„ë¼ì¸ ì„¸ì…˜ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ë° íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "project = Project()\n",
    "role = project.iam_role\n",
    "\n",
    "# ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "pipeline_session = PipelineSession()\n",
    "region = sagemaker_session.boto_region_name\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "pipeline_name = f\"bank-marketing-ml-pipeline\"\n",
    "model_package_group_name = f\"BankMarketingModelPackageGroup\"\n",
    "base_job_prefix = \"bank-marketing\"\n",
    "\n",
    "print(f\"âœ… íŒŒì´í”„ë¼ì¸ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - íŒŒì´í”„ë¼ì¸ ì´ë¦„: {pipeline_name}\")\n",
    "print(f\"   - ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹: {model_package_group_name}\")\n",
    "print(f\"   - ê¸°ë³¸ ë²„í‚·: {default_bucket}\")\n",
    "print(f\"   - ë¦¬ì „: {region}\")\n",
    "print(f\"   - IAM ì—­í• : {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-directories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "!mkdir -p pipeline_scripts\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parameters-section",
   "metadata": {},
   "source": [
    "## 3. íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œ ì¡°ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-parameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat\n",
    ")\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", \n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", \n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", \n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", \n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# ì„±ëŠ¥ ì„ê³„ê°’\n",
    "auc_score_threshold = ParameterFloat(\n",
    "    name=\"AucScoreThreshold\",\n",
    "    default_value=0.75\n",
    ")\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„° ê²½ë¡œ\n",
    "input_data_uri = ParameterString(\n",
    "    name=\"InputDataUri\",\n",
    "    default_value=f\"s3://{default_bucket}/bank-additional/bank-additional-full.csv\"\n",
    ")\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - ì²˜ë¦¬ ì¸ìŠ¤í„´ìŠ¤: {processing_instance_type.default_value}\")\n",
    "print(f\"   - í›ˆë ¨ ì¸ìŠ¤í„´ìŠ¤: {training_instance_type.default_value}\")\n",
    "print(f\"   - AUC ì„ê³„ê°’: {auc_score_threshold.default_value}\")\n",
    "print(f\"   - ëª¨ë¸ ìŠ¹ì¸ ìƒíƒœ: {model_approval_status.default_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-step",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„\n",
    "\n",
    "ì€í–‰ ë§ˆì¼€íŒ… ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"pipeline_scripts/bank_preprocess.py\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import argparse\n",
    "\n",
    "def preprocess_data():\n",
    "    \"\"\"ì€í–‰ ë§ˆì¼€íŒ… ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    input_path = f\"{base_dir}/input/bank-additional-full.csv\"\n",
    "    \n",
    "    print(f\"ë°ì´í„° ë¡œë“œ ì¤‘: {input_path}\")\n",
    "    df = pd.read_csv(input_path, sep=';')\n",
    "    \n",
    "    print(f\"ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}\")\n",
    "    print(f\"íƒ€ê²Ÿ ë¶„í¬: {df['y'].value_counts()}\")\n",
    "    \n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© (yes=1, no=0)\n",
    "    df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "    # ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©\n",
    "    categorical_columns = [\n",
    "        'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "        'contact', 'month', 'day_of_week', 'poutcome'\n",
    "    ]\n",
    "    \n",
    "    print(f\"ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©: {categorical_columns}\")\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    \n",
    "    print(f\"ì¸ì½”ë”© í›„ ë°ì´í„° í˜•íƒœ: {df_encoded.shape}\")\n",
    "    \n",
    "    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "    X = df_encoded.drop('y', axis=1)\n",
    "    y = df_encoded['y']\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í•  (70% í›ˆë ¨, 15% ê²€ì¦, 15% í…ŒìŠ¤íŠ¸)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=0.15, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 â‰ˆ 0.15/0.85\n",
    "    )\n",
    "    \n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]} ìƒ˜í”Œ\")\n",
    "    print(f\"ê²€ì¦ ë°ì´í„°: {X_val.shape[0]} ìƒ˜í”Œ\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]} ìƒ˜í”Œ\")\n",
    "    \n",
    "    # XGBoost í˜•ì‹ìœ¼ë¡œ ì €ì¥ (íƒ€ê²Ÿì´ ì²« ë²ˆì§¸ ì—´)\n",
    "    train_data = pd.concat([y_train, X_train], axis=1)\n",
    "    val_data = pd.concat([y_val, X_val], axis=1)\n",
    "    test_data = pd.concat([y_test, X_test], axis=1)\n",
    "    \n",
    "    # CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "    train_data.to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    val_data.to_csv(f\"{base_dir}/validation/validation.csv\", header=False, index=False)\n",
    "    test_data.to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)\n",
    "    \n",
    "    print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "    print(f\"   - í›ˆë ¨ ë°ì´í„° ì €ì¥: {base_dir}/train/train.csv\")\n",
    "    print(f\"   - ê²€ì¦ ë°ì´í„° ì €ì¥: {base_dir}/validation/validation.csv\")\n",
    "    print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥: {base_dir}/test/test.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-processing-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "# SKLearn í”„ë¡œì„¸ì„œ ìƒì„±\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=f\"{base_job_prefix}-preprocess\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "# ì „ì²˜ë¦¬ ë‹¨ê³„ ì¸ìˆ˜ ì •ì˜\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data_uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=f\"s3://{default_bucket}/{base_job_prefix}/data/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=f\"s3://{default_bucket}/{base_job_prefix}/data/validation\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=f\"s3://{default_bucket}/{base_job_prefix}/data/test\"\n",
    "        )\n",
    "    ],\n",
    "    code=\"pipeline_scripts/bank_preprocess.py\",\n",
    ")\n",
    "\n",
    "# ì „ì²˜ë¦¬ ë‹¨ê³„ ìƒì„±\n",
    "step_process = ProcessingStep(\n",
    "    name=\"BankMarketingDataProcess\",\n",
    "    step_args=processor_args\n",
    ")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - í”„ë¡œì„¸ì„œ: SKLearnProcessor\")\n",
    "print(f\"   - ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…: {processing_instance_type.default_value}\")\n",
    "print(f\"   - ì¶œë ¥ ê²½ë¡œ: s3://{default_bucket}/{base_job_prefix}/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-step",
   "metadata": {},
   "source": [
    "## 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë‹¨ê³„\n",
    "\n",
    "XGBoost ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ íŠœë‹í•˜ëŠ” ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-training-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "# XGBoost ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ URI\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.7-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "    \"early_stopping_rounds\": \"10\",\n",
    "    \"verbosity\": \"1\"\n",
    "}\n",
    "\n",
    "# XGBoost Estimator ìƒì„±\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=f\"s3://{default_bucket}/{base_job_prefix}/models\",\n",
    "    base_job_name=f\"{base_job_prefix}-train\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "print(f\"âœ… XGBoost Estimator ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì´ë¯¸ì§€ URI: {image_uri}\")\n",
    "print(f\"   - ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…: {training_instance_type.default_value}\")\n",
    "print(f\"   - ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„°: {fixed_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-hyperparameter-ranges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë²”ìœ„ ì •ì˜\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0.01, 0.3),           # í•™ìŠµë¥ \n",
    "    \"max_depth\": IntegerParameter(3, 10),            # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),  # ìµœì†Œ ìì‹ ê°€ì¤‘ì¹˜\n",
    "    \"subsample\": ContinuousParameter(0.7, 1.0),      # ì„œë¸Œìƒ˜í”Œë§ ë¹„ìœ¨\n",
    "    \"colsample_bytree\": ContinuousParameter(0.7, 1.0), # íŠ¹ì„± ì„œë¸Œìƒ˜í”Œë§\n",
    "    \"alpha\": ContinuousParameter(0, 2),              # L1 ì •ê·œí™”\n",
    "    \"lambda\": ContinuousParameter(1, 2),             # L2 ì •ê·œí™”\n",
    "}\n",
    "\n",
    "# ëª©ì  ë©”íŠ¸ë¦­\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë„ˆ ìƒì„±\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=6,        # ìµœëŒ€ íŠœë‹ ì‘ì—… ìˆ˜\n",
    "    max_parallel_jobs=2,  # ë³‘ë ¬ ì‹¤í–‰ ì‘ì—… ìˆ˜\n",
    "    objective_type=\"Maximize\",\n",
    "    base_tuning_job_name=f\"{base_job_prefix}-tuning\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë„ˆ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ëª©ì  ë©”íŠ¸ë¦­: {objective_metric_name}\")\n",
    "print(f\"   - ìµœëŒ€ ì‘ì—… ìˆ˜: 6ê°œ\")\n",
    "print(f\"   - ë³‘ë ¬ ì‘ì—… ìˆ˜: 2ê°œ\")\n",
    "print(f\"   - íŠœë‹ íŒŒë¼ë¯¸í„°: {list(hyperparameter_ranges.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-tuning-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë‹¨ê³„ ìƒì„±\n",
    "hpo_args = tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name=\"BankMarketingHyperParameterTuning\",\n",
    "    step_args=hpo_args,\n",
    ")\n",
    "\n",
    "print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë‹¨ê³„ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ë‹¨ê³„ ì´ë¦„: BankMarketingHyperParameterTuning\")\n",
    "print(f\"   - ì…ë ¥ ë°ì´í„°: ì „ì²˜ë¦¬ ë‹¨ê³„ì˜ train/validation ì¶œë ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-step",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ í‰ê°€ ë‹¨ê³„\n",
    "\n",
    "ìµœì  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€í•˜ëŠ” ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"pipeline_scripts/bank_evaluate.py\"\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model():\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ëª¨ë¸ í‰ê°€ ì‹œì‘\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}\")\n",
    "    \n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "    \n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘: {test_path}\")\n",
    "    \n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    X_test = df.iloc[:, 1:].values\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ: {X_test.shape}\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ë¶„í¬: {np.bincount(y_test)}\")\n",
    "    \n",
    "    # XGBoost DMatrix ìƒì„±\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    print(\"ğŸ“Š ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
    "    predictions_proba = model.predict(dtest)\n",
    "    predictions_binary = (predictions_proba > 0.5).astype(int)\n",
    "    \n",
    "    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    auc_score = roc_auc_score(y_test, predictions_proba)\n",
    "    accuracy = accuracy_score(y_test, predictions_binary)\n",
    "    \n",
    "    # í˜¼ë™ í–‰ë ¬\n",
    "    cm = confusion_matrix(y_test, predictions_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # ì¶”ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ“Š í‰ê°€ ê²°ê³¼:\")\n",
    "    print(f\"   - AUC: {auc_score:.4f}\")\n",
    "    print(f\"   - ì •í™•ë„: {accuracy:.4f}\")\n",
    "    print(f\"   - ì •ë°€ë„: {precision:.4f}\")\n",
    "    print(f\"   - ì¬í˜„ìœ¨: {recall:.4f}\")\n",
    "    print(f\"   - F1 ì ìˆ˜: {f1_score:.4f}\")\n",
    "    \n",
    "    # í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc_score\": {\n",
    "                \"value\": float(auc_score),\n",
    "                \"standard_deviation\": 0.0\n",
    "            },\n",
    "            \"accuracy\": {\n",
    "                \"value\": float(accuracy),\n",
    "                \"standard_deviation\": 0.0\n",
    "            },\n",
    "            \"precision\": {\n",
    "                \"value\": float(precision),\n",
    "                \"standard_deviation\": 0.0\n",
    "            },\n",
    "            \"recall\": {\n",
    "                \"value\": float(recall),\n",
    "                \"standard_deviation\": 0.0\n",
    "            },\n",
    "            \"f1_score\": {\n",
    "                \"value\": float(f1_score),\n",
    "                \"standard_deviation\": 0.0\n",
    "            }\n",
    "        },\n",
    "        \"confusion_matrix\": {\n",
    "            \"true_negative\": int(tn),\n",
    "            \"false_positive\": int(fp),\n",
    "            \"false_negative\": int(fn),\n",
    "            \"true_positive\": int(tp)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # í‰ê°€ ê²°ê³¼ ì €ì¥\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict, indent=2))\n",
    "    \n",
    "    print(f\"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {evaluation_path}\")\n",
    "    \n",
    "    return report_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-evaluation-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í‰ê°€ ë‹¨ê³„ ì •ì˜\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# ìŠ¤í¬ë¦½íŠ¸ í”„ë¡œì„¸ì„œ ìƒì„±\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "# í‰ê°€ ë‹¨ê³„ ì¸ìˆ˜ ì •ì˜\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(\n",
    "                top_k=0, \n",
    "                s3_bucket=default_bucket, \n",
    "                prefix=f\"{base_job_prefix}/models\"\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=f\"s3://{default_bucket}/{base_job_prefix}/evaluation\"\n",
    "        ),\n",
    "    ],\n",
    "    code=\"pipeline_scripts/bank_evaluate.py\",\n",
    ")\n",
    "\n",
    "# í‰ê°€ ë¦¬í¬íŠ¸ ì†ì„± íŒŒì¼\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"BankMarketingEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# í‰ê°€ ë‹¨ê³„ ìƒì„±\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"BankMarketingEvalModel\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í‰ê°€ ë‹¨ê³„ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ë‹¨ê³„ ì´ë¦„: BankMarketingEvalModel\")\n",
    "print(f\"   - ì…ë ¥: ìµœì  ëª¨ë¸ + í…ŒìŠ¤íŠ¸ ë°ì´í„°\")\n",
    "print(f\"   - ì¶œë ¥: í‰ê°€ ë¦¬í¬íŠ¸ (evaluation.json)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-registration",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ë“±ë¡ ë‹¨ê³„\n",
    "\n",
    "ì„±ëŠ¥ì´ ì„ê³„ê°’ì„ ë„˜ëŠ” ëª¨ë¸ì„ Model Registryì— ë“±ë¡í•˜ëŠ” ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(\n",
    "        top_k=0, \n",
    "        s3_bucket=default_bucket, \n",
    "        prefix=f\"{base_job_prefix}/models\"\n",
    "    ),\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë©”íŠ¸ë¦­ ì •ì˜\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë“±ë¡ ì¸ìˆ˜ ì •ì˜\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    "    description=\"ì€í–‰ ë§ˆì¼€íŒ… ìº í˜ì¸ ì •ê¸°ì˜ˆê¸ˆ ê°€ì… ì˜ˆì¸¡ ëª¨ë¸\",\n",
    "    model_name=\"BankMarketingXGBoostModel\"\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë“±ë¡ ë‹¨ê³„ ìƒì„±\n",
    "step_register = ModelStep(\n",
    "    name=\"BankMarketingRegisterModel\",\n",
    "    step_args=register_args\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë“±ë¡ ë‹¨ê³„ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹: {model_package_group_name}\")\n",
    "print(f\"   - ìŠ¹ì¸ ìƒíƒœ: {model_approval_status.default_value}\")\n",
    "print(f\"   - ì§€ì› ì¸ìŠ¤í„´ìŠ¤: ml.t2.medium, ml.m5.large, ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-step",
   "metadata": {},
   "source": [
    "## 8. ì¡°ê±´ë¶€ ë‹¨ê³„\n",
    "\n",
    "ëª¨ë¸ ì„±ëŠ¥ì´ ì„ê³„ê°’ì„ ë„˜ì„ ë•Œë§Œ ëª¨ë¸ì„ ë“±ë¡í•˜ëŠ” ì¡°ê±´ë¶€ ë¡œì§ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-conditional-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# AUC ì ìˆ˜ ì¡°ê±´ ì •ì˜\n",
    "cond_gte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=auc_score_threshold,\n",
    ")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ë‹¨ê³„ ìƒì„±\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreBankMarketingEvaluation\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register],  # AUCê°€ ì„ê³„ê°’ë³´ë‹¤ ë†’ìœ¼ë©´ ëª¨ë¸ ë“±ë¡\n",
    "    else_steps=[],             # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ\n",
    ")\n",
    "\n",
    "print(\"âœ… ì¡°ê±´ë¶€ ë‹¨ê³„ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì¡°ê±´: AUC > {auc_score_threshold.default_value}\")\n",
    "print(f\"   - Trueì¼ ë•Œ: ëª¨ë¸ ë“±ë¡\")\n",
    "print(f\"   - Falseì¼ ë•Œ: ì•„ë¬´ ì‘ì—… ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-creation",
   "metadata": {},
   "source": [
    "## 9. íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì •ì˜\n",
    "\n",
    "ëª¨ë“  ë‹¨ê³„ë¥¼ ì—°ê²°í•˜ì—¬ ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        auc_score_threshold,\n",
    "        input_data_uri,\n",
    "    ],\n",
    "    steps=[\n",
    "        step_process,    # 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        step_tuning,     # 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "        step_eval,       # 3. ëª¨ë¸ í‰ê°€\n",
    "        step_cond,       # 4. ì¡°ê±´ë¶€ ëª¨ë¸ ë“±ë¡\n",
    "    ],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - íŒŒì´í”„ë¼ì¸ ì´ë¦„: {pipeline_name}\")\n",
    "print(f\"   - ì´ ë‹¨ê³„ ìˆ˜: 4ê°œ\")\n",
    "print(f\"   - íŒŒë¼ë¯¸í„° ìˆ˜: 6ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì •ì˜ í™•ì¸\n",
    "definition = json.loads(pipeline.definition())\n",
    "\n",
    "print(\"ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì •ì˜ ìš”ì•½:\")\n",
    "print(f\"   - ë²„ì „: {definition['Version']}\")\n",
    "print(f\"   - íŒŒë¼ë¯¸í„° ìˆ˜: {len(definition['Parameters'])}\")\n",
    "print(f\"   - ë‹¨ê³„ ìˆ˜: {len(definition['Steps'])}\")\n",
    "\n",
    "print(f\"\\nğŸ”§ íŒŒë¼ë¯¸í„° ëª©ë¡:\")\n",
    "for param in definition['Parameters']:\n",
    "    print(f\"   - {param['Name']}: {param['Type']} (ê¸°ë³¸ê°’: {param['DefaultValue']})\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ë‹¨ê³„ ëª©ë¡:\")\n",
    "for step in definition['Steps']:\n",
    "    print(f\"   - {step['Name']}: {step['Type']}\")\n",
    "\n",
    "# ì „ì²´ ì •ì˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì‚¬í•­)\n",
    "with open('pipeline_definition.json', 'w') as f:\n",
    "    json.dump(definition, f, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ’¾ íŒŒì´í”„ë¼ì¸ ì •ì˜ê°€ 'pipeline_definition.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-execution",
   "metadata": {},
   "source": [
    "## 10. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "\n",
    "ì •ì˜ëœ íŒŒì´í”„ë¼ì¸ì„ SageMakerì— ë“±ë¡í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upsert-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ë“±ë¡/ì—…ë°ì´íŠ¸\n",
    "print(\"ğŸ”„ íŒŒì´í”„ë¼ì¸ ë“±ë¡ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    print(f\"âœ… íŒŒì´í”„ë¼ì¸ ë“±ë¡ ì™„ë£Œ: {pipeline_name}\")\n",
    "    \n",
    "    # íŒŒì´í”„ë¼ì¸ ì •ë³´ ì¶œë ¥\n",
    "    print(f\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ì •ë³´:\")\n",
    "    print(f\"   - ì´ë¦„: {pipeline.name}\")\n",
    "    print(f\"   - ARN: {pipeline.describe()['PipelineArn']}\")\n",
    "    print(f\"   - ìƒíƒœ: {pipeline.describe()['PipelineStatus']}\")\n",
    "    print(f\"   - ìƒì„± ì‹œê°„: {pipeline.describe()['CreationTime']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒŒì´í”„ë¼ì¸ ë“±ë¡ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"IAM ê¶Œí•œì´ë‚˜ ë¦¬ì†ŒìŠ¤ ì œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "start-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "print(\"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘...\")\n",
    "\n",
    "try:\n",
    "    execution = pipeline.start(\n",
    "        parameters={\n",
    "            \"ProcessingInstanceType\": \"ml.m5.xlarge\",\n",
    "            \"TrainingInstanceType\": \"ml.m5.xlarge\",\n",
    "            \"AucScoreThreshold\": 0.75,\n",
    "            \"ModelApprovalStatus\": \"PendingManualApproval\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘ë¨\")\n",
    "    print(f\"   - ì‹¤í–‰ ARN: {execution.arn}\")\n",
    "    print(f\"   - ì‹¤í–‰ ì´ë¦„: {execution.arn.split('/')[-1]}\")\n",
    "    \n",
    "    # ì‹¤í–‰ ìƒíƒœ í™•ì¸\n",
    "    print(f\"\\nğŸ“Š ì‹¤í–‰ ìƒíƒœ: {execution.describe()['PipelineExecutionStatus']}\")\n",
    "    print(f\"   - ì‹œì‘ ì‹œê°„: {execution.describe()['CreationTime']}\")\n",
    "    \n",
    "    # ì‹¤í–‰ ëª¨ë‹ˆí„°ë§ ì•ˆë‚´\n",
    "    print(f\"\\nğŸ’¡ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§:\")\n",
    "    print(f\"   - SageMaker Studio: íŒŒì´í”„ë¼ì¸ > {pipeline_name} > ì‹¤í–‰\")\n",
    "    print(f\"   - AWS ì½˜ì†”: SageMaker > íŒŒì´í”„ë¼ì¸ > {pipeline_name}\")\n",
    "    print(f\"   - ì˜ˆìƒ ì†Œìš” ì‹œê°„: 20-30ë¶„\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"íŒŒë¼ë¯¸í„°ë‚˜ ë¦¬ì†ŒìŠ¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-monitoring",
   "metadata": {},
   "source": [
    "## 11. íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "ì‹¤í–‰ ì¤‘ì¸ íŒŒì´í”„ë¼ì¸ì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ í™•ì¸\n",
    "if 'execution' in locals():\n",
    "    print(f\"ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ í™•ì¸: {execution.arn.split('/')[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # í˜„ì¬ ìƒíƒœ ì¡°íšŒ\n",
    "        status = execution.describe()\n",
    "        \n",
    "        print(f\"\\nğŸ” ì‹¤í–‰ ì •ë³´:\")\n",
    "        print(f\"   - ìƒíƒœ: {status['PipelineExecutionStatus']}\")\n",
    "        print(f\"   - ì‹œì‘ ì‹œê°„: {status['CreationTime']}\")\n",
    "        \n",
    "        if 'LastModifiedTime' in status:\n",
    "            print(f\"   - ë§ˆì§€ë§‰ ìˆ˜ì •: {status['LastModifiedTime']}\")\n",
    "        \n",
    "        if status['PipelineExecutionStatus'] == 'Failed':\n",
    "            print(f\"   - ì‹¤íŒ¨ ì´ìœ : {status.get('FailureReason', 'N/A')}\")\n",
    "        \n",
    "        # ë‹¨ê³„ë³„ ìƒíƒœ í™•ì¸\n",
    "        steps = execution.list_steps()\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ë‹¨ê³„ë³„ ìƒíƒœ:\")\n",
    "        for step in steps:\n",
    "            step_name = step['StepName']\n",
    "            step_status = step['StepStatus']\n",
    "            start_time = step.get('StartTime', 'N/A')\n",
    "            \n",
    "            status_emoji = {\n",
    "                'Executing': 'ğŸ”„',\n",
    "                'Succeeded': 'âœ…',\n",
    "                'Failed': 'âŒ',\n",
    "                'Stopping': 'â¸ï¸',\n",
    "                'Stopped': 'â¹ï¸'\n",
    "            }.get(step_status, 'â“')\n",
    "            \n",
    "            print(f\"   {status_emoji} {step_name}: {step_status}\")\n",
    "            if start_time != 'N/A':\n",
    "                print(f\"      ì‹œì‘ ì‹œê°„: {start_time}\")\n",
    "            \n",
    "            if step_status == 'Failed' and 'FailureReason' in step:\n",
    "                print(f\"      ì‹¤íŒ¨ ì´ìœ : {step['FailureReason']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì‹¤í–‰ ì¤‘ì¸ íŒŒì´í”„ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ìœ„ì˜ ì…€ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ëŒ€ê¸° (ì„ íƒì‚¬í•­)\n",
    "# ì£¼ì˜: ì´ ì…€ì€ íŒŒì´í”„ë¼ì¸ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì‹¤í–‰ë©ë‹ˆë‹¤ (20-30ë¶„ ì†Œìš”)\n",
    "\n",
    "WAIT_FOR_COMPLETION = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°\n",
    "\n",
    "if WAIT_FOR_COMPLETION and 'execution' in locals():\n",
    "    print(\"â³ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ëŒ€ê¸° ì¤‘...\")\n",
    "    print(\"   ì´ ê³¼ì •ì€ 20-30ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ì¤‘ë‹¨í•˜ë ¤ë©´ ì»¤ë„ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    try:\n",
    "        execution.wait(delay=60, max_attempts=60)  # ìµœëŒ€ 60ë¶„ ëŒ€ê¸°\n",
    "        \n",
    "        final_status = execution.describe()\n",
    "        print(f\"\\nğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!\")\n",
    "        print(f\"   - ìµœì¢… ìƒíƒœ: {final_status['PipelineExecutionStatus']}\")\n",
    "        print(f\"   - ì™„ë£Œ ì‹œê°„: {final_status.get('LastModifiedTime', 'N/A')}\")\n",
    "        \n",
    "        if final_status['PipelineExecutionStatus'] == 'Succeeded':\n",
    "            print(f\"   âœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ íŒŒì´í”„ë¼ì¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"ğŸ’¡ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ëŒ€ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    print(\"   ì™„ë£Œ ìƒíƒœë¥¼ í™•ì¸í•˜ë ¤ë©´ ìœ„ì˜ ëª¨ë‹ˆí„°ë§ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    print(\"   ë˜ëŠ” WAIT_FOR_COMPLETIONì„ Trueë¡œ ì„¤ì •í•˜ê³  ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-management",
   "metadata": {},
   "source": [
    "## 12. íŒŒì´í”„ë¼ì¸ ê´€ë¦¬\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ì˜ ì‹¤í–‰ ì´ë ¥ì„ ì¡°íšŒí•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-executions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ\n",
    "print(f\"ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì´ë ¥: {pipeline_name}\")\n",
    "\n",
    "try:\n",
    "    executions = pipeline.list_executions()\n",
    "    \n",
    "    if executions:\n",
    "        print(f\"\\nì´ {len(executions)}ê°œì˜ ì‹¤í–‰ ê¸°ë¡ì´ ìˆìŠµë‹ˆë‹¤:\")\n",
    "        \n",
    "        for i, exec_summary in enumerate(executions[:5], 1):  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ\n",
    "            exec_name = exec_summary['PipelineExecutionArn'].split('/')[-1]\n",
    "            status = exec_summary['PipelineExecutionStatus']\n",
    "            start_time = exec_summary['StartTime']\n",
    "            \n",
    "            status_emoji = {\n",
    "                'Executing': 'ğŸ”„',\n",
    "                'Succeeded': 'âœ…',\n",
    "                'Failed': 'âŒ',\n",
    "                'Stopping': 'â¸ï¸',\n",
    "                'Stopped': 'â¹ï¸'\n",
    "            }.get(status, 'â“')\n",
    "            \n",
    "            print(f\"   {i}. {status_emoji} {exec_name}\")\n",
    "            print(f\"      ìƒíƒœ: {status}\")\n",
    "            print(f\"      ì‹œì‘: {start_time}\")\n",
    "            \n",
    "            if 'PipelineExecutionDescription' in exec_summary:\n",
    "                print(f\"      ì„¤ëª…: {exec_summary['PipelineExecutionDescription']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"   ì‹¤í–‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-model-registry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í™•ì¸\n",
    "print(f\"ğŸª ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í™•ì¸: {model_package_group_name}\")\n",
    "\n",
    "try:\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    \n",
    "    # ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹ ì¡´ì¬ í™•ì¸\n",
    "    try:\n",
    "        group_info = sm_client.describe_model_package_group(\n",
    "            ModelPackageGroupName=model_package_group_name\n",
    "        )\n",
    "        print(f\"âœ… ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹ ì¡´ì¬: {model_package_group_name}\")\n",
    "        print(f\"   - ìƒì„± ì‹œê°„: {group_info['CreationTime']}\")\n",
    "        print(f\"   - ìƒíƒœ: {group_info['ModelPackageGroupStatus']}\")\n",
    "        \n",
    "        # ë“±ë¡ëœ ëª¨ë¸ íŒ¨í‚¤ì§€ ì¡°íšŒ\n",
    "        packages = sm_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "        \n",
    "        if packages['ModelPackageSummaryList']:\n",
    "            print(f\"\\nğŸ“¦ ë“±ë¡ëœ ëª¨ë¸ íŒ¨í‚¤ì§€ ({len(packages['ModelPackageSummaryList'])}ê°œ):\")\n",
    "            \n",
    "            for i, package in enumerate(packages['ModelPackageSummaryList'][:3], 1):\n",
    "                print(f\"   {i}. {package['ModelPackageArn'].split('/')[-1]}\")\n",
    "                print(f\"      ìƒíƒœ: {package['ModelPackageStatus']}\")\n",
    "                print(f\"      ìŠ¹ì¸: {package['ModelApprovalStatus']}\")\n",
    "                print(f\"      ìƒì„±: {package['CreationTime']}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"   ë“±ë¡ëœ ëª¨ë¸ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            print(\"   íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ê³  AUC ì„ê³„ê°’ì„ ë„˜ì–´ì•¼ ëª¨ë¸ì´ ë“±ë¡ë©ë‹ˆë‹¤.\")\n",
    "            \n",
    "    except sm_client.exceptions.ResourceNotFound:\n",
    "        print(f\"âš ï¸ ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {model_package_group_name}\")\n",
    "        print(\"   íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cicd-section",
   "metadata": {},
   "source": [
    "## 13. CI/CD ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ì„ CI/CD ì‹œìŠ¤í…œê³¼ í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cicd-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI/CD í†µí•©ì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ íŠ¸ë¦¬ê±° í•¨ìˆ˜\n",
    "def trigger_pipeline_execution(\n",
    "    pipeline_name,\n",
    "    parameters=None,\n",
    "    execution_display_name=None\n",
    "):\n",
    "    \"\"\"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ íŠ¸ë¦¬ê±°í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        if parameters is None:\n",
    "            parameters = {\n",
    "                \"ProcessingInstanceType\": \"ml.m5.xlarge\",\n",
    "                \"TrainingInstanceType\": \"ml.m5.xlarge\",\n",
    "                \"AucScoreThreshold\": 0.75,\n",
    "                \"ModelApprovalStatus\": \"PendingManualApproval\"\n",
    "            }\n",
    "        \n",
    "        # ì‹¤í–‰ ì´ë¦„ ìƒì„±\n",
    "        if execution_display_name is None:\n",
    "            timestamp = strftime('%Y%m%d-%H%M%S', gmtime())\n",
    "            execution_display_name = f\"pipeline-execution-{timestamp}\"\n",
    "        \n",
    "        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "        execution = pipeline.start(\n",
    "            parameters=parameters,\n",
    "            execution_display_name=execution_display_name\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'execution_arn': execution.arn,\n",
    "            'execution_name': execution.arn.split('/')[-1],\n",
    "            'message': f'íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {execution_display_name}'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'message': f'íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}'\n",
    "        }\n",
    "\n",
    "# ì˜ˆì œ ì‹¤í–‰\n",
    "print(\"ğŸ”§ CI/CD í†µí•© í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\")\n",
    "print(\"```python\")\n",
    "print(\"result = trigger_pipeline_execution(\")\n",
    "print(\"    pipeline_name='bank-marketing-ml-pipeline',\")\n",
    "print(\"    parameters={'AucScoreThreshold': 0.8},\")\n",
    "print(\"    execution_display_name='production-deployment'\")\n",
    "print(\")\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-webhook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹í›… ìŠ¤íƒ€ì¼ API ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì œ\n",
    "def create_pipeline_webhook_handler():\n",
    "    \"\"\"Lambda í•¨ìˆ˜ë‚˜ API Gatewayì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì›¹í›… í•¸ë“¤ëŸ¬ ì˜ˆì œ\"\"\"\n",
    "    \n",
    "    webhook_code = '''\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ Lambda í•¸ë“¤ëŸ¬\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # SageMaker í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "        \n",
    "        # ìš”ì²­ íŒŒë¼ë¯¸í„° íŒŒì‹±\n",
    "        body = json.loads(event.get('body', '{}'))\n",
    "        \n",
    "        pipeline_name = body.get('pipeline_name', 'bank-marketing-ml-pipeline')\n",
    "        parameters = body.get('parameters', {})\n",
    "        \n",
    "        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        default_params = {\n",
    "            'ProcessingInstanceType': 'ml.m5.xlarge',\n",
    "            'TrainingInstanceType': 'ml.m5.xlarge',\n",
    "            'AucScoreThreshold': '0.75',\n",
    "            'ModelApprovalStatus': 'PendingManualApproval'\n",
    "        }\n",
    "        \n",
    "        # íŒŒë¼ë¯¸í„° ë³‘í•©\n",
    "        final_params = {**default_params, **parameters}\n",
    "        \n",
    "        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "        response = sagemaker_client.start_pipeline_execution(\n",
    "            PipelineName=pipeline_name,\n",
    "            PipelineParameters=[\n",
    "                {'Name': k, 'Value': str(v)} for k, v in final_params.items()\n",
    "            ],\n",
    "            PipelineExecutionDisplayName=f\"webhook-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({\n",
    "                'success': True,\n",
    "                'execution_arn': response['PipelineExecutionArn'],\n",
    "                'message': 'Pipeline execution started successfully'\n",
    "            })\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'message': 'Pipeline execution failed'\n",
    "            })\n",
    "        }\n",
    "'''\n",
    "    \n",
    "    return webhook_code\n",
    "\n",
    "# ì›¹í›… ì½”ë“œ ìƒì„± ë° ì €ì¥\n",
    "webhook_code = create_pipeline_webhook_handler()\n",
    "\n",
    "with open('pipeline_webhook.py', 'w') as f:\n",
    "    f.write(webhook_code)\n",
    "\n",
    "print(\"ğŸŒ ì›¹í›… í•¸ë“¤ëŸ¬ ì½”ë“œ ìƒì„± ì™„ë£Œ\")\n",
    "print(\"   - íŒŒì¼: pipeline_webhook.py\")\n",
    "print(\"   - ìš©ë„: Lambda í•¨ìˆ˜ë‚˜ API Gatewayì—ì„œ ì‚¬ìš©\")\n",
    "print(\"   - ê¸°ëŠ¥: HTTP ìš”ì²­ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ íŠ¸ë¦¬ê±°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 14. íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "êµ¬ì¶•ëœ ML íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ì ì¸ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²°ê³¼ ìš”ì•½\n",
    "print(\"ğŸ“‹ SageMaker ML íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ğŸ—ï¸ êµ¬ì¶•ëœ íŒŒì´í”„ë¼ì¸:\")\n",
    "print(f\"   - ì´ë¦„: {pipeline_name}\")\n",
    "print(f\"   - ëª¨ë¸ íŒ¨í‚¤ì§€ ê·¸ë£¹: {model_package_group_name}\")\n",
    "print(f\"   - ê¸°ë³¸ ë²„í‚·: {default_bucket}\")\n",
    "\n",
    "print(f\"\\nğŸ”§ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ:\")\n",
    "print(f\"   1. ë°ì´í„° ì „ì²˜ë¦¬ (SKLearnProcessor)\")\n",
    "print(f\"      - ì€í–‰ ë§ˆì¼€íŒ… ë°ì´í„° ì „ì²˜ë¦¬\")\n",
    "print(f\"      - ì›-í•« ì¸ì½”ë”© ë° ë°ì´í„° ë¶„í• \")\n",
    "print(f\"   2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (XGBoost)\")\n",
    "print(f\"      - 6ê°œ ì‘ì—…, 2ê°œ ë³‘ë ¬ ì‹¤í–‰\")\n",
    "print(f\"      - AUC ìµœì í™”\")\n",
    "print(f\"   3. ëª¨ë¸ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)\")\n",
    "print(f\"      - AUC, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ê³„ì‚°\")\n",
    "print(f\"   4. ì¡°ê±´ë¶€ ëª¨ë¸ ë“±ë¡\")\n",
    "print(f\"      - AUC > {auc_score_threshold.default_value}ì¼ ë•Œë§Œ ë“±ë¡\")\n",
    "\n",
    "print(f\"\\nâš™ï¸ íŒŒë¼ë¯¸í„° ì„¤ì •:\")\n",
    "print(f\"   - ì²˜ë¦¬ ì¸ìŠ¤í„´ìŠ¤: {processing_instance_type.default_value}\")\n",
    "print(f\"   - í›ˆë ¨ ì¸ìŠ¤í„´ìŠ¤: {training_instance_type.default_value}\")\n",
    "print(f\"   - AUC ì„ê³„ê°’: {auc_score_threshold.default_value}\")\n",
    "print(f\"   - ìŠ¹ì¸ ìƒíƒœ: {model_approval_status.default_value}\")\n",
    "\n",
    "print(f\"\\nğŸš€ ì‹¤í–‰ ë°©ë²•:\")\n",
    "print(f\"   - SageMaker Studio: íŒŒì´í”„ë¼ì¸ íƒ­ì—ì„œ ì‹¤í–‰\")\n",
    "print(f\"   - í”„ë¡œê·¸ë˜ë°: pipeline.start() ë©”ì„œë“œ\")\n",
    "print(f\"   - CI/CD: ì›¹í›… ë˜ëŠ” Lambda í•¨ìˆ˜\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ëª¨ë‹ˆí„°ë§:\")\n",
    "print(f\"   - ì‹¤í–‰ ìƒíƒœ: execution.describe()\")\n",
    "print(f\"   - ë‹¨ê³„ë³„ ë¡œê·¸: CloudWatch Logs\")\n",
    "print(f\"   - ëª¨ë¸ ë“±ë¡: Model Registry\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   1. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§\")\n",
    "print(f\"   2. ë“±ë¡ëœ ëª¨ë¸ ìŠ¹ì¸ ë° ë°°í¬\")\n",
    "print(f\"   3. CI/CD ì‹œìŠ¤í…œê³¼ í†µí•©\")\n",
    "print(f\"   4. ìŠ¤ì¼€ì¤„ë§ ë° ìë™í™” ì„¤ì •\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ ML íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì™„ë£Œ!\")\n",
    "print(\"ì´ì œ ìë™í™”ëœ ML ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ ëª¨ë¸ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
