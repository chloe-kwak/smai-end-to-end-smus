{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ecce4ad-8973-41f1-9128-92263225b788",
   "metadata": {},
   "source": [
    "# [Lab2] 모델 훈련 with SageMaker Training\n",
    "\n",
    "이 노트북에서는 SageMaker Training Job을 사용하여 XGBoost 모델을 훈련합니다.\n",
    "\n",
    "## 주요 내용\n",
    "- SageMaker Built-in 알고리즘을 사용한 모델 훈련\n",
    "- 다양한 하이퍼파라미터 설정으로 모델 비교\n",
    "- MLflow를 통한 실험 추적 및 모델 등록\n",
    "- Script Mode를 사용한 커스텀 훈련\n",
    "- 자동 로깅 기능 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61aa426-39f5-4576-9e70-2a2c19693dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 노트북에서 저장한 변수들 로드\n",
    "%store -r\n",
    "\n",
    "print(\"✅ 저장된 변수들을 로드했습니다.\")\n",
    "print(f\"   - S3 버킷: {bucket}\")\n",
    "print(f\"   - 훈련 데이터 경로: {train_path}\")\n",
    "print(f\"   - 검증 데이터 경로: {validation_path}\")\n",
    "print(f\"   - 실험 이름: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cd0d7-6d66-4754-9d91-36b3fccd7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from IPython.display import Javascript\n",
    "\n",
    "# AWS 세션 초기화\n",
    "boto_session = boto3.Session()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 및 세션 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a47dc5-fbf6-4eff-b7fc-dba0dfb6ca65",
   "metadata": {},
   "source": [
    "## 2. 훈련 데이터 준비\n",
    "\n",
    "전처리된 데이터를 SageMaker Training Job에서 사용할 수 있도록 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30267e-688d-40f9-9690-69569dca9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 컨테이너 이미지 URI 가져오기\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework='xgboost', \n",
    "    version='1.7-1'\n",
    ")\n",
    "\n",
    "print(f\"✅ XGBoost 컨테이너 이미지: {container}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0364f-e50e-4568-8ee7-69981acf753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 입력 데이터 설정\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=train_path, \n",
    "    content_type='csv'\n",
    ")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=validation_path, \n",
    "    content_type='csv'\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    'train': s3_input_train, \n",
    "    'validation': s3_input_validation\n",
    "}\n",
    "\n",
    "print(\"✅ 훈련 입력 데이터 설정 완료\")\n",
    "print(f\"   - 훈련 데이터: {train_path}\")\n",
    "print(f\"   - 검증 데이터: {validation_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdad486-f85a-459a-a7ec-edf1b858dda6",
   "metadata": {},
   "source": [
    "## 3. MLflow 실험 설정\n",
    "\n",
    "모델 훈련 과정을 추적하기 위한 MLflow 설정을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab546085-a67f-43e8-930f-7d08cad2748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 및 MLflow 설정\n",
    "from sagemaker_studio import Project\n",
    "\n",
    "project = Project()\n",
    "arn = project.mlflow_tracking_server_arn\n",
    "role = project.iam_role\n",
    "domain_id = project.domain_id\n",
    "project_id= project.id\n",
    "\n",
    "mlflow.set_tracking_uri(arn)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "# 사용자 프로필 정보 설정\n",
    "user_profile_name = os.getenv('USER', 'sagemaker-user')\n",
    "\n",
    "print(f\"✅ MLflow 실험 설정 완료\")\n",
    "print(f\"   - 추적 URI: {arn}\")\n",
    "print(f\"   - 실험 이름: {experiment_name}\")\n",
    "print(f\"   - 사용자: {user_profile_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "builtin-training",
   "metadata": {},
   "source": [
    "## 4. Built-in 알고리즘을 사용한 모델 훈련\n",
    "\n",
    "SageMaker의 Built-in XGBoost 알고리즘을 사용하여 두 가지 다른 하이퍼파라미터 설정으로 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5a1a0-10dd-477c-a741-cbb5b17ab4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 모델 설정 (보수적인 하이퍼파라미터)\n",
    "xgb1 = sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{bucket}/{prefix}/output/',\n",
    "    base_job_name='conservative-xgb-training',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# 보수적인 하이퍼파라미터 설정\n",
    "xgb1.set_hyperparameters(\n",
    "    max_depth=3,\n",
    "    eta=0.5,\n",
    "    gamma=4,\n",
    "    eval_metric=\"auc\",\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    verbosity=0,\n",
    "    objective='binary:logistic',\n",
    "    num_round=50\n",
    ")\n",
    "\n",
    "print(\"✅ 첫 번째 모델 (보수적 설정) 구성 완료\")\n",
    "print(f\"   - 학습률(eta): 0.5\")\n",
    "print(f\"   - 최대 깊이: 3\")\n",
    "print(f\"   - 라운드 수: 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-model-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 모델 설정 (적극적인 하이퍼파라미터)\n",
    "xgb2 = sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{bucket}/{prefix}/output/',\n",
    "    base_job_name='aggressive-xgb-training',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# 적극적인 하이퍼파라미터 설정\n",
    "xgb2.set_hyperparameters(\n",
    "    max_depth=3,\n",
    "    eta=0.1,\n",
    "    gamma=2,\n",
    "    eval_metric=\"auc\",\n",
    "    min_child_weight=3,\n",
    "    subsample=0.4,\n",
    "    verbosity=0,\n",
    "    objective='binary:logistic',\n",
    "    num_round=100\n",
    ")\n",
    "\n",
    "print(\"✅ 두 번째 모델 (적극적 설정) 구성 완료\")\n",
    "print(f\"   - 학습률(eta): 0.1\")\n",
    "print(f\"   - 최대 깊이: 3\")\n",
    "print(f\"   - 라운드 수: 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-execution",
   "metadata": {},
   "source": [
    "## 5. MLflow 실험 시작 및 모델 훈련\n",
    "\n",
    "MLflow 실험을 시작하고 두 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlflow-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 이름 생성\n",
    "run_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "run_name = f\"model-training-{run_suffix}\"\n",
    "\n",
    "# MLflow 실행 시작\n",
    "run_id = mlflow.start_run(\n",
    "    run_name=run_name, \n",
    "    description=\"SageMaker Built-in XGBoost를 사용한 모델 훈련\"\n",
    ").info.run_id\n",
    "\n",
    "print(f\"✅ MLflow 실행 시작: {run_name}\")\n",
    "print(f\"   - 실행 ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeddeef-848a-4477-9f15-f0f9dc32f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 모델 훈련 시작 (비동기)\n",
    "print(\"🚀 첫 번째 모델 훈련 시작 (백그라운드)...\")\n",
    "xgb1.fit(training_inputs, wait=False, logs=False)\n",
    "\n",
    "print(f\"✅ 첫 번째 모델 훈련 작업 시작: {xgb1.latest_training_job.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfadbe-04d9-4137-8a06-6eddd6f73990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 모델 훈련 시작 (동기)\n",
    "print(\"🚀 두 번째 모델 훈련 시작 (대기)...\")\n",
    "xgb2.fit(training_inputs, wait=True, logs=False)\n",
    "\n",
    "print(f\"✅ 두 번째 모델 훈련 완료: {xgb2.latest_training_job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-progress",
   "metadata": {},
   "source": [
    "## ⏳ 훈련 진행 중...\n",
    "\n",
    "모델 훈련이 진행 중입니다. 완료될 때까지 잠시 기다려주세요.\n",
    "\n",
    "- 첫 번째 모델: 보수적 설정으로 빠른 훈련\n",
    "- 두 번째 모델: 적극적 설정으로 정밀한 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-logging",
   "metadata": {},
   "source": [
    "## 6. MLflow 수동 로깅\n",
    "\n",
    "현재 실행 중인 MLflow 실험에 훈련된 모델의 정보를 로깅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29702e7-d53e-441a-98d2-caee5daa509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_data_s3_uri):\n",
    "    \"\"\"S3에서 훈련된 XGBoost 모델을 로드하는 함수\"\"\"\n",
    "    import xgboost as xgb\n",
    "    import tarfile\n",
    "    import pickle as pkl\n",
    "\n",
    "    model_file = \"./xgboost-model.tar.gz\"\n",
    "    bucket, key = model_data_s3_uri.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "    boto3.client(\"s3\").download_file(bucket, key, model_file)\n",
    "    \n",
    "    with tarfile.open(model_file, \"r:gz\") as t:\n",
    "        t.extractall(path=\".\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(\"xgboost-model\")\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"✅ 모델 로딩 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-mlflow-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow 실행 상태 확인 및 정리\n",
    "try:\n",
    "    # 현재 활성화된 실행이 있는지 확인\n",
    "    active_run = mlflow.active_run()\n",
    "    if active_run:\n",
    "        print(f\"⚠️ 활성화된 MLflow 실행 발견: {active_run.info.run_id}\")\n",
    "        if active_run.info.run_id != run_id:\n",
    "            print(\"   다른 실행이 활성화되어 있습니다. 종료합니다.\")\n",
    "            mlflow.end_run()\n",
    "        else:\n",
    "            print(\"   현재 실행과 동일합니다. 계속 진행합니다.\")\n",
    "    else:\n",
    "        print(\"✅ 활성화된 MLflow 실행이 없습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"MLflow 상태 확인 중 오류: {e}\")\n",
    "    # 안전하게 모든 실행 종료\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "log-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 활성화된 MLflow 실행에 두 모델의 정보 로깅\n",
    "# 이미 활성화된 실행이 있으므로 새로운 start_run 없이 직접 로깅\n",
    "\n",
    "# 첫 번째 모델 정보 로깅\n",
    "print(\"📝 첫 번째 모델 정보 로깅...\")\n",
    "mlflow.log_params({\n",
    "    \"model1_eta\": 0.5,\n",
    "    \"model1_max_depth\": 3,\n",
    "    \"model1_gamma\": 4,\n",
    "    \"model1_min_child_weight\": 6,\n",
    "    \"model1_subsample\": 0.8,\n",
    "    \"model1_num_round\": 50,\n",
    "    \"model1_training_job\": xgb1.latest_training_job.name\n",
    "})\n",
    "\n",
    "# 두 번째 모델 정보 로깅\n",
    "print(\"📝 두 번째 모델 정보 로깅...\")\n",
    "mlflow.log_params({\n",
    "    \"model2_eta\": 0.1,\n",
    "    \"model2_max_depth\": 3,\n",
    "    \"model2_gamma\": 2,\n",
    "    \"model2_min_child_weight\": 3,\n",
    "    \"model2_subsample\": 0.4,\n",
    "    \"model2_num_round\": 100,\n",
    "    \"model2_training_job\": xgb2.latest_training_job.name\n",
    "})\n",
    "\n",
    "# 태그 설정\n",
    "mlflow.set_tags({\n",
    "    'mlflow.user': user_profile_name,\n",
    "    'mlflow.source.type': 'TRAINING_JOB',\n",
    "    'model.algorithm': 'XGBoost',\n",
    "    'model.framework': 'Built-in',\n",
    "    'training.approach': 'hyperparameter_comparison'\n",
    "})\n",
    "\n",
    "# 메트릭 로깅 시도\n",
    "try:\n",
    "    # 첫 번째 모델 메트릭\n",
    "    metrics1 = xgb1.training_job_analytics.dataframe('auc')\n",
    "    for _, row in metrics1.iterrows():\n",
    "        if row['metric_name'] in ['train:auc', 'validation:auc']:\n",
    "            mlflow.log_metric(f\"model1_{row['metric_name'].replace(':', '_')}\", row['value'])\n",
    "    \n",
    "    # 두 번째 모델 메트릭\n",
    "    metrics2 = xgb2.training_job_analytics.dataframe('auc')\n",
    "    for _, row in metrics2.iterrows():\n",
    "        if row['metric_name'] in ['train:auc', 'validation:auc']:\n",
    "            mlflow.log_metric(f\"model2_{row['metric_name'].replace(':', '_')}\", row['value'])\n",
    "            \n",
    "    print(\"✅ 메트릭 로깅 완료\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 메트릭 로깅 실패: {e}\")\n",
    "\n",
    "# 모델 아티팩트 로깅 시도\n",
    "try:\n",
    "    model1 = load_model(xgb1.model_data)\n",
    "    mlflow.xgboost.log_model(model1, artifact_path=\"model1\")\n",
    "    \n",
    "    model2 = load_model(xgb2.model_data)\n",
    "    mlflow.xgboost.log_model(model2, artifact_path=\"model2\")\n",
    "    \n",
    "    print(\"✅ 모델 아티팩트 로깅 완료\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 모델 로깅 실패: {e}\")\n",
    "\n",
    "print(f\"✅ MLflow 로깅 완료 (Run ID: {run_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b962bb-d4fe-4bbd-a7d2-55bfe45fd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 이름 생성\n",
    "timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "test_name_1 = \"conservative-hyperparams\"\n",
    "run_name_1 = f\"{test_name_1}-training-{timestamp}\"\n",
    "\n",
    "test_name_2 = \"aggressive-hyperparams\"\n",
    "run_name_2 = f\"{test_name_2}-training-{timestamp}\"\n",
    "\n",
    "print(f\"✅ 실행 이름 생성 완료\")\n",
    "print(f\"   - 첫 번째 실행: {run_name_1}\")\n",
    "print(f\"   - 두 번째 실행: {run_name_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-registration",
   "metadata": {},
   "source": [
    "## 7. 모델 등록\n",
    "\n",
    "훈련된 모델들을 MLflow Model Registry에 등록하여 버전 관리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4ad47-22c4-4936-bda0-f3b9eff5ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등록할 모델 이름 설정\n",
    "registered_model_name = f\"bank-marketing-model-{experiment_name.split('-')[-1]}\"\n",
    "\n",
    "print(f\"✅ 모델 등록 이름: {registered_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fce149-92da-4df2-8c18-1e982df3ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 모델 등록\n",
    "print(\"📋 첫 번째 모델을 Model Registry에 등록 중...\")\n",
    "\n",
    "model_uri_1 = f\"runs:/{run_id}/model1\"  # run_id 사용, model1 경로\n",
    "registered_model_version_1 = mlflow.register_model(\n",
    "    model_uri_1, \n",
    "    registered_model_name\n",
    ")\n",
    "\n",
    "print(f\"✅ 첫 번째 모델 등록 완료\")\n",
    "print(f\"   - 모델 이름: {registered_model_name}\")\n",
    "print(f\"   - 버전: {registered_model_version_1.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580bbac4-c46d-497a-87a8-7ff9c6c820e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 모델 등록\n",
    "print(\"📋 두 번째 모델을 Model Registry에 등록 중...\")\n",
    "\n",
    "model_uri_2 = f\"runs:/{run_id}/model2\"  # run_id 사용, model2 경로\n",
    "registered_model_version_2 = mlflow.register_model(\n",
    "    model_uri_2, \n",
    "    registered_model_name\n",
    ")\n",
    "\n",
    "print(f\"✅ 두 번째 모델 등록 완료\")\n",
    "print(f\"   - 모델 이름: {registered_model_name}\")\n",
    "print(f\"   - 버전: {registered_model_version_2.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-viewing",
   "metadata": {},
   "source": [
    "## 8. 훈련 결과 확인\n",
    "\n",
    "MLflow UI에서 훈련 결과를 확인할 수 있는 링크를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d5835-67f7-467c-be88-1e1542441d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 실행 정보 가져오기\n",
    "latest_runs = mlflow.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id], \n",
    "    max_results=2, \n",
    "    order_by=[\"attributes.start_time DESC\"]\n",
    ")\n",
    "\n",
    "# MLflow UI 링크 생성\n",
    "presigned_url = sess.sagemaker_client.create_presigned_mlflow_tracking_server_url(\n",
    "    TrackingServerName=mlflow_name,\n",
    "    ExpiresInSeconds=60,\n",
    "    SessionExpirationDurationInSeconds=1800\n",
    ")['AuthorizedUrl']\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "mlflow_experiment_link = f\"{presigned_url.split('/auth')[0]}/#/experiments/{experiment_id}\"\n",
    "\n",
    "print(\"✅ MLflow UI 링크 생성 완료\")\n",
    "print(f\"   - 실험 페이지: {mlflow_experiment_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707c1c6-0d4f-421b-9705-7aa0d487fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow UI 자동 열기\n",
    "print(\"🌐 MLflow UI를 새 탭에서 열고 있습니다...\")\n",
    "display(Javascript(f'window.open(\"{mlflow_experiment_link}\");'))\n",
    "\n",
    "print(\"\\n📊 MLflow UI에서 다음을 확인할 수 있습니다:\")\n",
    "print(\"   - 두 모델의 하이퍼파라미터 비교\")\n",
    "print(\"   - 훈련/검증 AUC 메트릭 비교\")\n",
    "print(\"   - 모델 아티팩트 및 메타데이터\")\n",
    "print(\"   - 훈련 작업 링크\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "script-mode-section",
   "metadata": {},
   "source": [
    "## 9. Script Mode를 사용한 커스텀 훈련\n",
    "\n",
    "더 세밀한 제어와 자동 로깅을 위해 Script Mode를 사용하여 커스텀 훈련 스크립트로 모델을 훈련합니다.\n",
    "\n",
    "### Script Mode의 장점\n",
    "- 커스텀 훈련 로직 구현 가능\n",
    "- MLflow 자동 로깅 기능 활용\n",
    "- 분산 훈련 지원\n",
    "- 더 유연한 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028cfc9-fc92-4904-bc04-f23dac31481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 스크립트 디렉토리 생성\n",
    "!mkdir -p './training'\n",
    "\n",
    "print(\"✅ 훈련 스크립트 디렉토리 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451bfd3-53d2-4d46-8deb-8d76ccee71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile './training/requirements.txt'\n",
    "mlflow==2.13.2\n",
    "sagemaker-mlflow==0.1.0\n",
    "sagemaker-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-script-section",
   "metadata": {},
   "source": [
    "### 커스텀 훈련 스크립트 작성\n",
    "\n",
    "MLflow 자동 로깅과 SageMaker 환경을 활용하는 훈련 스크립트를 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./training/train.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"필수 패키지 설치\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Installing MLflow packages...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'mlflow==2.13.2', '--quiet'])\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker-mlflow==0.1.0', '--quiet'])\n",
    "        logger.info(\"MLflow packages installed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Package installation failed: {e}\")\n",
    "        logger.info(\"Continuing without MLflow...\")\n",
    "\n",
    "# 패키지 설치\n",
    "install_requirements()\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers import entry_point\n",
    "    from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "    from sagemaker_xgboost_container import distributed\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import xgboost as xgb\n",
    "    import mlflow\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    logger.warning(f\"Import error: {e}\")\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "def _xgb_train(params, dtrain, dval, evals, num_boost_round, model_dir, is_master):\n",
    "    \"\"\"XGBoost 훈련 함수\"\"\"\n",
    "    logger.info(f\"Starting XGBoost training with params: {params}\")\n",
    "    \n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        evals=evals,\n",
    "        num_boost_round=num_boost_round,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # 메트릭 계산\n",
    "    val_auc = roc_auc_score(dval.get_label(), booster.predict(dval))\n",
    "    train_auc = roc_auc_score(dtrain.get_label(), booster.predict(dtrain))\n",
    "    \n",
    "    logger.info(f\"Training AUC: {train_auc:.4f}\")\n",
    "    logger.info(f\"Validation AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # MLflow 로깅 (사용 가능한 경우)\n",
    "    if MLFLOW_AVAILABLE and os.getenv('MLFLOW_TRACKING_ARN'):\n",
    "        try:\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics({\"validation_auc\": val_auc, \"train_auc\": train_auc})\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"MLflow logging failed: {e}\")\n",
    "    \n",
    "    # SageMaker 메트릭 출력\n",
    "    print(f\"[0]#011train-auc:{train_auc}#011validation-auc:{val_auc}\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    if is_master:\n",
    "        model_location = os.path.join(model_dir, 'xgboost-model')\n",
    "        with open(model_location, 'wb') as f:\n",
    "            pkl.dump(booster, f)\n",
    "        logger.info(f\"Model saved to: {model_location}\")\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"명령행 인수 파싱\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # 하이퍼파라미터\n",
    "    parser.add_argument('--max_depth', type=int, default=3)\n",
    "    parser.add_argument('--eta', type=float, default=0.1)\n",
    "    parser.add_argument('--gamma', type=int, default=0)\n",
    "    parser.add_argument('--min_child_weight', type=float, default=1)\n",
    "    parser.add_argument('--subsample', type=float, default=1.0)\n",
    "    parser.add_argument('--colsample_bytree', type=float, default=1.0)\n",
    "    parser.add_argument('--verbosity', type=int, default=1)\n",
    "    parser.add_argument('--objective', type=str, default='binary:logistic')\n",
    "    parser.add_argument('--num_round', type=int, default=100)\n",
    "    parser.add_argument('--early_stopping_rounds', type=int, default=10)\n",
    "    parser.add_argument('--tree_method', type=str, default=\"auto\")\n",
    "    parser.add_argument('--predictor', type=str, default=\"auto\")\n",
    "\n",
    "    # SageMaker 환경 변수\n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "    parser.add_argument('--sm_training_env', type=str, default=os.environ.get('SM_TRAINING_ENV'))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 함수\"\"\"\n",
    "    try:\n",
    "        args, _ = parse_args()\n",
    "        logger.info(\"Training started\")\n",
    "        logger.info(f\"Hyperparameters: eta={args.eta}, max_depth={args.max_depth}, num_round={args.num_round}\")\n",
    "\n",
    "        # 환경 변수 확인\n",
    "        suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "        user_profile_name = os.getenv('USER', 'sagemaker-user')\n",
    "        experiment_name = os.getenv('MLFLOW_EXPERIMENT_NAME')\n",
    "        region = os.getenv('REGION')\n",
    "        mlflow_arn = os.getenv('MLFLOW_TRACKING_ARN')\n",
    "\n",
    "        logger.info(f\"Environment - User: {user_profile_name}, Region: {region}\")\n",
    "        \n",
    "        # SageMaker 환경 정보\n",
    "        sm_hosts = json.loads(args.sm_hosts) if args.sm_hosts else ['localhost']\n",
    "        sm_current_host = args.sm_current_host or 'localhost'\n",
    "        sm_training_env = json.loads(args.sm_training_env) if args.sm_training_env else {}\n",
    "        \n",
    "        # 데이터 로드\n",
    "        logger.info(\"Loading training data...\")\n",
    "        dtrain = get_dmatrix(args.train, 'CSV')\n",
    "        dval = get_dmatrix(args.validation, 'CSV')\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'validation')] if dval is not None else [(dtrain, 'train')]\n",
    "        \n",
    "        logger.info(f\"Data loaded - Train: {dtrain.num_row()} rows, Validation: {dval.num_row()} rows\")\n",
    "        \n",
    "        # MLflow 설정 (사용 가능한 경우)\n",
    "        if MLFLOW_AVAILABLE and mlflow_arn:\n",
    "            try:\n",
    "                mlflow.set_tracking_uri(mlflow_arn)\n",
    "                mlflow.set_experiment(experiment_name=experiment_name if experiment_name else f\"script-training-{suffix}\")\n",
    "                mlflow.xgboost.autolog(log_model_signatures=False, log_datasets=False)\n",
    "                logger.info(\"MLflow configured successfully\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"MLflow setup failed: {e}\")\n",
    "\n",
    "        # 훈련 하이퍼파라미터 설정\n",
    "        train_hp = {\n",
    "            'max_depth': args.max_depth,\n",
    "            'eta': args.eta,\n",
    "            'gamma': args.gamma,\n",
    "            'min_child_weight': args.min_child_weight,\n",
    "            'subsample': args.subsample,\n",
    "            'colsample_bytree': args.colsample_bytree,\n",
    "            'verbosity': 0,  # 로그 출력 최소화\n",
    "            'objective': args.objective,\n",
    "            'tree_method': args.tree_method,\n",
    "            'predictor': args.predictor,\n",
    "        }\n",
    "\n",
    "        xgb_train_args = {\n",
    "            'params': train_hp,\n",
    "            'dtrain': dtrain,\n",
    "            'dval': dval,\n",
    "            'evals': watchlist,\n",
    "            'num_boost_round': args.num_round,\n",
    "            'model_dir': args.model_dir\n",
    "        }\n",
    "\n",
    "        # MLflow 실행 시작 (사용 가능한 경우)\n",
    "        if MLFLOW_AVAILABLE and mlflow_arn:\n",
    "            try:\n",
    "                with mlflow.start_run(\n",
    "                    run_name=f\"script-mode-training-{suffix}\",\n",
    "                    description=\"SageMaker Script Mode XGBoost Training\"\n",
    "                ) as run:\n",
    "                    # 태그 설정\n",
    "                    mlflow.set_tags({\n",
    "                        'mlflow.user': user_profile_name,\n",
    "                        'mlflow.source.type': 'TRAINING_JOB',\n",
    "                        'model.framework': 'Script-Mode',\n",
    "                        'training.mode': 'script'\n",
    "                    })\n",
    "                    \n",
    "                    # 훈련 실행\n",
    "                    _execute_training(sm_hosts, sm_current_host, dtrain, xgb_train_args)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"MLflow run failed: {e}\")\n",
    "                # MLflow 없이 훈련 진행\n",
    "                _execute_training(sm_hosts, sm_current_host, dtrain, xgb_train_args)\n",
    "        else:\n",
    "            logger.info(\"Training without MLflow\")\n",
    "            _execute_training(sm_hosts, sm_current_host, dtrain, xgb_train_args)\n",
    "        \n",
    "        logger.info(\"Training completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "def _execute_training(sm_hosts, sm_current_host, dtrain, xgb_train_args):\n",
    "    \"\"\"훈련 실행 함수\"\"\"\n",
    "    if len(sm_hosts) > 1:\n",
    "        logger.info(f\"Distributed training with {len(sm_hosts)} hosts\")\n",
    "        entry_point._wait_hostname_resolution()\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Single node training\")\n",
    "        if dtrain:\n",
    "            xgb_train_args['is_master'] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"No training data available\")\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"모델 로드 함수 (추론용)\"\"\"\n",
    "    model_file = 'xgboost-model'\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        booster = pkl.load(f)\n",
    "    return booster\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "script-hyperparams",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 및 환경 변수 설정\n",
    "\n",
    "Script Mode 훈련을 위한 하이퍼파라미터와 환경 변수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparams-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Mode용 하이퍼파라미터 설정\n",
    "script_hyperparams = {\n",
    "    'num_round': 75,\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.2,\n",
    "    'gamma': 1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 2,\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "# 환경 변수 설정 (Project 클래스 활용)\n",
    "env_variables = {\n",
    "    'MLFLOW_TRACKING_ARN': arn,  # Project에서 가져온 MLflow ARN\n",
    "    'MLFLOW_EXPERIMENT_NAME': experiment_name,\n",
    "    'USER': user_profile_name,\n",
    "    'REGION': region,\n",
    "}\n",
    "\n",
    "print(\"✅ Script Mode 하이퍼파라미터 설정 완료\")\n",
    "print(f\"   - 학습률(eta): {script_hyperparams['eta']}\")\n",
    "print(f\"   - 최대 깊이: {script_hyperparams['max_depth']}\")\n",
    "print(f\"   - 라운드 수: {script_hyperparams['num_round']}\")\n",
    "print(f\"   - MLflow ARN: {env_variables['MLFLOW_TRACKING_ARN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "script-estimator",
   "metadata": {},
   "source": [
    "### Script Mode Estimator 생성\n",
    "\n",
    "XGBoost Script Mode Estimator를 생성하고 훈련을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "script-estimator-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Mode Estimator 생성 (Unified Studio 환경 최적화)\n",
    "xgb_script_mode = XGBoost(\n",
    "    entry_point='train.py',  # 새로운 스크립트 사용\n",
    "    source_dir='./training',\n",
    "    framework_version=\"1.7-1\",  \n",
    "    hyperparameters=script_hyperparams,\n",
    "    role=role,  # Project에서 가져온 역할\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{bucket}/{prefix}/script-output/',\n",
    "    code_location=f's3://{bucket}/{prefix}/code/',  # 코드 업로드 경로 명시\n",
    "    base_job_name=\"unified-studio-xgb-training\",\n",
    "    environment=env_variables\n",
    ")\n",
    "\n",
    "print(\"✅ Unified Studio Script Mode Estimator 생성 완료\")\n",
    "print(f\"   - 프레임워크 버전: 1.7-1\")\n",
    "print(f\"   - 인스턴스 타입: ml.m5.large\")\n",
    "print(f\"   - 출력 경로: s3://{bucket}/{prefix}/script-output/\")\n",
    "print(f\"   - 코드 업로드 경로: s3://{bucket}/{prefix}/code/\")\n",
    "print(f\"   - Unified Studio 최적화 스크립트 사용\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "script-training",
   "metadata": {},
   "source": [
    "### Script Mode 훈련 실행\n",
    "\n",
    "커스텀 스크립트를 사용하여 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "script-training-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Mode 훈련 실행\n",
    "print(\"🚀 Script Mode 훈련 시작...\")\n",
    "print(\"   - 커스텀 훈련 스크립트 사용\")\n",
    "print(\"   - MLflow 자동 로깅 활성화\")\n",
    "print(\"   - 실시간 메트릭 추적\")\n",
    "\n",
    "# 로그 활성화로 디버깅\n",
    "xgb_script_mode.fit(training_inputs, wait=True, logs=True)\n",
    "\n",
    "print(f\"✅ Script Mode 훈련 완료!\")\n",
    "print(f\"   - 훈련 작업: {xgb_script_mode.latest_training_job.name}\")\n",
    "print(f\"   - 모델 S3 URI: {xgb_script_mode.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "script-results",
   "metadata": {},
   "source": [
    "### Script Mode 결과 확인\n",
    "\n",
    "Script Mode로 훈련된 모델의 결과를 MLflow UI에서 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "script-results-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Mode 훈련 결과 확인\n",
    "try:\n",
    "    # 최신 실행 정보 가져오기\n",
    "    latest_runs = mlflow.search_runs(\n",
    "        experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id], \n",
    "        max_results=1, \n",
    "        order_by=[\"attributes.start_time DESC\"]\n",
    "    )\n",
    "    \n",
    "    if not latest_runs.empty:\n",
    "        latest_run_id = latest_runs['run_id'][0]\n",
    "        \n",
    "        # MLflow UI 링크 생성\n",
    "        presigned_url = sess.sagemaker_client.create_presigned_mlflow_tracking_server_url(\n",
    "            TrackingServerName=mlflow_name,\n",
    "            ExpiresInSeconds=60,\n",
    "            SessionExpirationDurationInSeconds=1800\n",
    "        )['AuthorizedUrl']\n",
    "        \n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        script_run_link = f\"{presigned_url.split('/auth')[0]}/#/experiments/{experiment_id}/runs/{latest_run_id}\"\n",
    "        \n",
    "        print(\"✅ Script Mode 훈련 결과 확인\")\n",
    "        print(f\"   - 최신 실행 ID: {latest_run_id}\")\n",
    "        print(f\"   - MLflow UI: {script_run_link}\")\n",
    "        \n",
    "        # MLflow UI 자동 열기\n",
    "        print(\"\\n🌐 MLflow UI를 새 탭에서 열고 있습니다...\")\n",
    "        display(Javascript(f'window.open(\"{script_run_link}\");'))\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ MLflow 실행 정보를 찾을 수 없습니다.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ MLflow 결과 확인 중 오류: {e}\")\n",
    "\n",
    "print(\"\\n📊 Script Mode에서 확인 가능한 정보:\")\n",
    "print(\"   - 자동 로깅된 하이퍼파라미터\")\n",
    "print(\"   - 훈련/검증 AUC 메트릭\")\n",
    "print(\"   - 모델 아티팩트 (자동 저장)\")\n",
    "print(\"   - 훈련 과정 로그\")\n",
    "print(\"   - SageMaker 훈련 작업 링크\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "store-variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 노트북에서 사용할 변수들 저장\n",
    "%store run_name_1\n",
    "%store registered_model_version_1\n",
    "%store registered_model_version_2\n",
    "%store registered_model_name\n",
    "\n",
    "print(\"✅ 변수 저장 완료\")\n",
    "print(\"\\n📋 저장된 정보:\")\n",
    "print(f\"   - 등록된 모델 이름: {registered_model_name}\")\n",
    "print(f\"   - 모델 버전 1: {registered_model_version_1.version}\")\n",
    "print(f\"   - 모델 버전 2: {registered_model_version_2.version}\")\n",
    "print(f\"   - 실행 ID 1: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completion",
   "metadata": {},
   "source": [
    "## ✅ 모델 훈련 완료\n",
    "\n",
    "SageMaker Training Job을 사용한 XGBoost 모델 훈련이 성공적으로 완료되었습니다!\n",
    "\n",
    "### 완료된 작업\n",
    "- ✅ 두 가지 하이퍼파라미터 설정으로 XGBoost 모델 훈련\n",
    "- ✅ MLflow를 통한 실험 추적 및 메트릭 로깅\n",
    "- ✅ 훈련된 모델을 Model Registry에 등록\n",
    "- ✅ 모델 성능 비교를 위한 MLflow UI 링크 생성\n",
    "\n",
    "### 훈련된 모델\n",
    "1. **보수적 모델**: 빠른 학습률(0.5), 적은 라운드(50)\n",
    "2. **적극적 모델**: 느린 학습률(0.1), 많은 라운드(100)\n",
    "\n",
    "### 다음 단계\n",
    "이제 `3-test-and-deploy.ipynb` 노트북으로 진행하여:\n",
    "- 훈련된 모델들의 성능 평가\n",
    "- 최적 모델 선택\n",
    "- SageMaker 엔드포인트로 모델 배포\n",
    "- 실시간 추론 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43b508-7d88-45c6-91ea-ec4fc626d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 완료 요약\n",
    "print(\"🎉 모델 훈련 완료!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📊 첫 번째 모델 (보수적 하이퍼파라미터):\")\n",
    "print(f\"   - 훈련 작업명: {xgb1.latest_training_job.name}\")\n",
    "print(f\"   - 모델 S3 URI: {xgb1.model_data}\")\n",
    "print(f\"   - 하이퍼파라미터: {xgb1.hyperparameters()}\")\n",
    "\n",
    "print(f\"\\n📊 두 번째 모델 (적극적 하이퍼파라미터):\")\n",
    "print(f\"   - 훈련 작업명: {xgb2.latest_training_job.name}\")\n",
    "print(f\"   - 모델 S3 URI: {xgb2.model_data}\")\n",
    "print(f\"   - 하이퍼파라미터: {xgb2.hyperparameters()}\")\n",
    "\n",
    "print(f\"\\n📜 Script Mode 모델:\")\n",
    "print(f\"   - 훈련 작업명: {xgb_script_mode.latest_training_job.name}\")\n",
    "print(f\"   - 모델 S3 URI: {xgb_script_mode.model_data}\")\n",
    "print(f\"   - MLflow 실행 ID: {run_id}\")\n",
    "\n",
    "print(\"\\n✅ 모든 모델이 성공적으로 훈련되었습니다!\")\n",
    "print(\"   다음 단계: 3-model-evaluation.ipynb에서 성능 평가\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69268533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 노트북에서 사용할 변수들 저장\n",
    "%store run_id\n",
    "#%store xgb1\n",
    "#%store xgb2\n",
    "#%store xgb_script_mode\n",
    "%store registered_model_name\n",
    "%store registered_model_version_1\n",
    "%store registered_model_version_2\n",
    "\n",
    "# 모델 URI도 별도로 저장 (배포 단계에서 사용)\n",
    "model1_uri = xgb1.model_data\n",
    "model2_uri = xgb2.model_data\n",
    "%store model1_uri\n",
    "%store model2_uri\n",
    "\n",
    "print(\"✅ 변수 저장 완료\")\n",
    "print(\"\\n📋 저장된 정보:\")\n",
    "print(f\"   - MLflow 실행 ID: {run_id}\")\n",
    "print(f\"   - 등록된 모델 이름: {registered_model_name}\")\n",
    "print(f\"   - 모델 버전 1: {registered_model_version_1.version}\")\n",
    "print(f\"   - 모델 버전 2: {registered_model_version_2.version}\")\n",
    "print(f\"\\n🔧 Built-in 알고리즘 모델:\")\n",
    "print(f\"   - 첫 번째 모델 훈련 작업: {xgb1.latest_training_job.name}\")\n",
    "print(f\"   - 두 번째 모델 훈련 작업: {xgb2.latest_training_job.name}\")\n",
    "print(f\"   - 첫 번째 모델 S3 URI: {xgb1.model_data}\")\n",
    "print(f\"   - 두 번째 모델 S3 URI: {xgb2.model_data}\")\n",
    "print(f\"\\n📜 Script Mode 모델:\")\n",
    "print(f\"   - Script Mode 훈련 작업: {xgb_script_mode.latest_training_job.name}\")\n",
    "print(f\"   - Script Mode 모델 S3 URI: {xgb_script_mode.model_data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
